bigrams_tdm
?filter
read_txt_tibble <- function(path = file.choose(), encoding = "UTF-8") {
#interactively reads txt files into tibbles
vector <- readLines(path, encoding = encoding)
tibble <- tibble(line = 1:length(vector), text = vector)
tibble
}
blogs <- read_txt_tibble("C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\en_US.blogs.txt")
news <- read_txt_tibble("C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\en_US.news.txt")
twitter <- read_txt_tibble("C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\en_US.twitter.txt")
#merging data
data <- bind_rows(mutate(blogs, source = "blogs"),
mutate(news, source = "news"),
mutate(twitter, source = "twitter"))
rm(blogs, news, twitter)
##### Sampling #####
set.seed(2137)
data <- sample_frac(data, size = 0.2)
#####
#Cleaning
#Removing non-ASCII characters, then stripping whitespace
data <- data %>%
mutate(text =  gsub("[^\x20-\x7E]", "", text)) %>%
mutate(text = gsub("[ ]+", " ", text))
#tokenizing into sentences
#we do that in order to avoid trigrams spanning more than 1 sentence
sentences <- data %>%
unnest_tokens(sentence, text, token = "sentences")
rm(data)
#cleaning punctuation and numbers and NAs
sentences <- sentences %>%
mutate(sentence = gsub("[^a-z ']","", sentence)) %>%
mutate(sentence = gsub("[ ]+", " ", sentence)) %>%
mutate(sentence = gsub(" +$", "", sentence)) %>%
filtrer(!is.na(sentence))
#cleaning punctuation and numbers and NAs
sentences <- sentences %>%
mutate(sentence = gsub("[^a-z ']","", sentence)) %>%
mutate(sentence = gsub("[ ]+", " ", sentence)) %>%
mutate(sentence = gsub(" +$", "", sentence)) %>%
filter(!is.na(sentence))
sentences
filter(sentences, is.na(sentence))
bigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 2)
filter(bigrams, is.na(phrase))
bigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 2) %>%
filter(!is.na(phrase))
save(bigrams, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\bigrams")
trigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 3) %>%
filter(!is.na(phrase))
format(object.size(bigrams), units = "Mb")
format(object.size(trigrams), units = "Mb")
save(trigrams, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\trigrams")
bigrams_tdm <- bigrams %>%
group_by(phrase) %>%
summarise(n = n())
bigrams_tdm
?sort
bigrams_tdm <- bigrams %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n))
bigrams_tdm
format(object.size(bigrams_tdm), units = "Mb")
trigrams_tdm <- trigrams %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n))
format(object.size(trigrams_tdm), units = "Mb")
trigrams_tdm
save(bigrams_tdm, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\bigrams_tdm")
save(trigrams_tdm, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\trigrams_tdm")
rm(bigrams, sentences, trigrams)
format(object.size(bigrams_tdm), units = "Mb")
bigrams_df <- as.matrix(bigrams_tdm)
head(bigrams_df)
format(object.size(bigrams_df), units = "Mb")
rm(bigrams_df)
read_txt_tibble <- function(path = file.choose(), encoding = "UTF-8") {
#interactively reads txt files into tibbles
vector <- readLines(path, encoding = encoding)
tibble <- tibble(line = 1:length(vector), text = vector)
tibble
}
blogs <- read_txt_tibble("C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\en_US.blogs.txt")
news <- read_txt_tibble("C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\en_US.news.txt")
twitter <- read_txt_tibble("C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\en_US.twitter.txt")
#merging data
data <- bind_rows(mutate(blogs, source = "blogs"),
mutate(news, source = "news"),
mutate(twitter, source = "twitter"))
rm(blogs, news, twitter)
##### Sampling #####
set.seed(2137)
data <- sample_frac(data, size = 0.2)
#####
#Cleaning
#Removing non-ASCII characters, then stripping whitespace
data <- data %>%
mutate(text =  gsub("[^\x20-\x7E]", "", text)) %>%
mutate(text = gsub("[ ]+", " ", text))
#tokenizing into sentences
#we do that in order to avoid trigrams spanning more than 1 sentence
sentences <- data %>%
unnest_tokens(sentence, text, token = "sentences")
rm(data)
#cleaning punctuation and numbers and NAs
sentences <- sentences %>%
mutate(sentence = gsub("[^a-z ']","", sentence)) %>%
mutate(sentence = gsub("[ ]+", " ", sentence)) %>%
mutate(sentence = gsub(" +$", "", sentence))
unigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "words") %>%
filter(!is.na(phrase))
bigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 2) %>%
filter(!is.na(phrase))
trigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 3) %>%
filter(!is.na(phrase))
unigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "words") %>%
filter(!is.na(phrase)) %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(n > 3)
tail(unigrams)
bigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 2) %>%
filter(!is.na(phrase)) %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(n > 3)
trigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 3) %>%
filter(!is.na(phrase)) %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(n > 3)
rm(trigrams)
bigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 2) %>%
filter(!is.na(phrase)) %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(n > 3)
gc()
gc()
trigrams <- sentences %>%
unnest_tokens(phrase, sentence, token = "ngrams", n = 3) %>%
filter(!is.na(phrase)) %>%
group_by(phrase) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(n > 3)
rm(sentences)
tail(unigrams)
tail(bigrams)
tail(trigrams)
save(unigrams_tdm, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\unigrams")
save(unigrams, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\unigrams")
save(bigrams, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\bigrams")
save(trigrams, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\trigrams")
gc()
library(dplyr)
?load
unigrams <- load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\unigrams")
bigrams <- load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\bigrams")
trigrams <- load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\trigrams")
unigrams
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\unigrams")
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\bigrams")
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\trigrams")
model.data <- list(unigrams, bigrams, trigrams)
model.data[[1]]
length(model.data)
?setClass
rm(model.data)
SBOdata <- list(unigrams, bigrams, trigrams)
save(SBOdata, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\SBOdata")
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\SBOdata")
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\bigrams")
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\trigrams")
View(bigrams)
?separate
library(dplyr)
library(dplyr)
library(tidytext)
library(tidyr)
?separate
load(file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\unigrams")
names(unigrams)
names(unigrams)[1] <- "word_1"
separate(bigrams, phrase, into = c("word_1", "word_2"), sep = " ")
bigrams <- separate(bigrams, phrase, into = c("word_1", "word_2"), sep = " ")
trigrams <- separate(trigrams, phrase, into = c("word_1", "word_2", "word_3"), sep = " ")
View(trigrams)
SBOdata <- list(unigrams, bigrams, trigrams)
save(SBOdata, file = "C:\\Users\\jakub.wiatrak\\Desktop\\final\\en_US\\SBOdata")
library(tidytext)
??punctutation
cleanText <- function(str) {
#converts toLower, leaves only letters, strips whitespaces
out <- tolower(str)
out <- gsub("[^a-z ']","", out)
out <- gsub("[ ]+", " ", out)
out <- gsub(" +$", "", out)
return(out)
}
cleanText("We're excited to announce that Data Science Capstone is now open. Be sure to complete your assignments by the weekly deadlines. The dead")
?strsplit
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
}
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
v
}
getWords("fdsa fdsaf fdsaf ff ")
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
out <- v[length(v) - maxN + 1, length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
out <- v[length(v) - maxN + 1:length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
out <- v[(length(v) - maxN + 1):length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
print(v)
out <- v[(length(v) - maxN + 1):length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")
print(v)
print(length(v))
out <- v[(length(v) - maxN + 1):length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
strsplit("fdsa fdsaf fdsaf ff ", split = " ")
strsplit("fdsa fdsaf fdsaf ff ", split = " ")[[1]]
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")[[1]]
out <- v[(length(v) - maxN + 1):length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
getWords <- function(str, maxN = 3) {
# gets the last N-1 words from a text input
v <- strsplit(str, split = " ")[[1]]
out <- v[(length(v) - maxN + 2):length(v)]
out
}
getWords("fdsa fdsaf fdsaf ff ")
10:1
1:1
length(getWords(""))
bigrams
filter(bigrams, 1 = "of")
filter(bigrams, 1 == "of")
filter(bigrams, .[[1]] == "of")
filter(bigrams, [[1]] == "of")
filter(bigrams, bigrams[[1]] == "of")
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
n <- length(pre) + 1
matched <- data[[1]]
for(i in 1:length(pre)) {
word <- pre[i]
matched <- filter(matched, matched[[i]] == word)
}
matched
}
tail(trigrams)
debug(matchNgrams)
matchNgrams(c("zombies", "on"))
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
n <- length(pre) + 1
matched <- data[[n]]
for(i in 1:length(pre)) {
word <- pre[i]
matched <- filter(matched, matched[[i]] == word)
}
matched
}
debug(matchNgrams)
matchNgrams(c("zombies", "on"))
undebug(matchNgrams)
matchNgrams(c("using", "the"))
matchNgrams(c("using"))
matchNgrams(c(""))
c("")[0]
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
n <- length(pre) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(pre)) {
word <- pre[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched
}
matchNgrams(c(""))
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
n <- length(pre) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(pre)) {
word <- pre[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched
}
matchNgrams(c("on", "the"))
matchNgrams(c("on"))
debug(matchNgrams)
matchNgrams(c(""))
length(c(""))
length(c())
undebug(matchNgrams)
"" == c("")
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
n <- length(pre) + 1
matched <- data[[n]]
if(n>1 & pre != "") {
for(i in 1:length(pre)) {
word <- pre[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched
}
matchNgrams(c(""))
test <- c("", "a", "", "b")
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
words <- pre[pre != ""]
n <- length(words) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched
}
matchNgrams(c(""))
matchNgrams(c("thx"))
?count
2:0
c("a", "b", "c")
c("a", "b", "c")[0]
c("a", "b", "c")[0:2]
c("a", "b", "c")[0:)]
c("a", "b", "c")[0:0]
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
words <- pre[pre != ""]
n <- length(words) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched[,ncol(matched)-1:ncol(matched)]
}
matchNgrams(c("the", "best"))
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
words <- pre[pre != ""]
n <- length(words) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched[,(ncol(matched)-1:ncol(matched))]
}
matchNgrams(c("the", "best"))
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
words <- pre[pre != ""]
n <- length(words) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched[,(ncol(matched))]
}
matchNgrams(c("the", "best"))
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
words <- pre[pre != ""]
n <- length(words) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched[,3:(ncol(matched))]
}
matchNgrams(c("the", "best"))
matchNgrams <- function(pre, data = SBOdata) {
#pre - one or more words (as a char vector) (from getWords())
words <- pre[pre != ""]
n <- length(words) + 1
matched <- data[[n]]
if(n>1) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
matched[,(ncol(matched)-1):ncol(matched)]
}
matchNgrams(c("the", "best"))
matchNgrams(c("best"))
matchNgrams(c(""))
getNmatches <- function(phrase, data = SBOdata) {
#for length 0 and 1 it will return the same thing
words <- phrase[pre != ""]
matched <- data[[length(words)]]
if(length(words)>0) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
sum(matched$n, na.rm = T)
}
getNmatches(c("on", "the"))
getNmatches <- function(phrase, data = SBOdata) {
#for length 0 and 1 it will return the same thing
words <- phrase[phrase != ""]
matched <- data[[length(words)]]
if(length(words)>0) {
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
sum(matched$n, na.rm = T)
}
getNmatches(c("on", "the"))
filter(bigrams, word_1 == "on", word_2 =="the")
getNmatches(c("the"))
unigrams
getNmatches(c(""))
debug(getNmatches)
getNmatches(c(""))
getNmatches <- function(phrase, data = SBOdata) {
#for length 0 and 1 it will return the same thing
words <- phrase[phrase != ""]
if(length(words)==0) {
matched <- data[[1]]
} else {
matched <- data[[length(words)]]
for(i in 1:length(words)) {
word <- words[i]
matched <- filter(matched, matched[[i]] == word)
}
}
sum(matched$n, na.rm = T)
}
debug(getNmatches)
getNmatches(c(""))
sum(unigrams$n)
