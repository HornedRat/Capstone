library(tm)
library(wordcloud)
library(ngram)
library(ggplot2)

#Choose the 'en_us' folder with data
data.path <- choose.dir()

collection <- VCorpus(DirSource(data.path, encoding = "UTF-8"))

summary(collection)
head(collection[[1]]$content)

# Counting lines, characters and words

textDesc <- function(txt) {
    lines <- length(txt)
    words <- wordcount(txt)
    avgChar <- mean(nchar(txt))
    avgWords <- words / lines
    c(lines = lines, words = words, avgChar = avgChar, avgWords = avgWords)
}

rbind(c(title = collection[[1]]$meta$id, textDesc(collection[[1]]$content)),
      c(title = collection[[2]]$meta$id, textDesc(collection[[2]]$content)),
      c(title = collection[[3]]$meta$id, textDesc(collection[[3]]$content)))

# Sampling to save memory and computing time
set.seed(2137)

blogs_sample <- sample(collection[[1]]$content, 1000)
news_sample <- sample(collection[[2]]$content, 1000)
twitter_sample <- sample(collection[[3]]$content, 1000)
collection <- VCorpus(VectorSource(list(blogs_sample,
                                        news_sample,
                                        twitter_sample)))


# Cleaning

profanities <- readLines("profanities.txt")

collection <- tm_map(collection, content_transformer(tolower))
collection <- tm_map(collection, removeWords, stopwords())
collection <- tm_map(collection, removeWords, profanities)
collection <- tm_map(collection, removePunctuation, ucp = T)
collection <- tm_map(collection, removeNumbers)
#collection <- tm_map(collection, stemDocument) #produces unexpected results
collection <- tm_map(collection, stripWhitespace)

# Exploration

# most common words - wordclouds
png("blogs.png")
wordcloud(collection[[1]]$content, max.words = 100, random.order = FALSE,colors=brewer.pal(8, "Dark2"))
dev.off()
png("news.png")
wordcloud(collection[[2]]$content, max.words = 100, random.order = FALSE,colors=brewer.pal(8, "Dark2"))
dev.off()
png("twitter.png")
wordcloud(collection[[3]]$content, max.words = 100, random.order = FALSE,colors=brewer.pal(8, "Dark2"))
dev.off()

#most common words
tdm <- TermDocumentMatrix(collection)
inspect(tdm)

head(sort(as.matrix(tdm)[,1], decreasing = T), 20)
head(sort(as.matrix(tdm)[,2], decreasing = T), 20)
head(sort(as.matrix(tdm)[,3], decreasing = T), 20)

blogs_1grams <- data.frame(word = names(head(sort(as.matrix(tdm)[,1], decreasing = T), 20)),
                freq = head(sort(as.matrix(tdm)[,1], decreasing = T), 20))
news_1grams <- data.frame(word = names(head(sort(as.matrix(tdm)[,2], decreasing = T), 20)),
                           freq = head(sort(as.matrix(tdm)[,2], decreasing = T), 20))
twitter_1grams <- data.frame(word = names(head(sort(as.matrix(tdm)[,3], decreasing = T), 20)),
                           freq = head(sort(as.matrix(tdm)[,3], decreasing = T), 20))


g1 <- ggplot(blogs_1grams, aes(x = reorder(word, freq),y=freq)) +
    geom_bar(stat = "identity") +
    coord_flip()
g1

g2 <- ggplot(news_1grams, aes(x = reorder(word, freq),y=freq)) +
    geom_bar(stat = "identity") +
    coord_flip()
g2

g3 <- ggplot(twitter_1grams, aes(x = reorder(word, freq),y=freq)) +
    geom_bar(stat = "identity") +
    coord_flip()
g3

